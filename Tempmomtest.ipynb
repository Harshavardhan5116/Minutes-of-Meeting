{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRw2KpU25qYu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dYLaQsqEfs5",
        "outputId": "1bac0ae5-bbba-40f3-a045-ef04b8c80b85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-8o_gbd5d\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-8o_gbd5d\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.14.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802826 sha256=f7cc744b6b890ad7adf11b0a571fa24bfb057f58279ec1601f9767ed679dffd1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-r12wrt24/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6zmpb5aEjKL",
        "outputId": "14548bf2-7b9c-44f0-9b58-139d1be2fe80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Collecting whisper\n",
            "  Downloading whisper-1.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from whisper) (1.16.0)\n",
            "Building wheels for collected packages: whisper\n",
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper: filename=whisper-1.1.10-py3-none-any.whl size=41120 sha256=d8e3548b05d5814f717d480aaa481347b7a6f39f78a12026ec7018c05ce6a5e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/7c/1d/015619716e2facae6631312503baf3c3220e6a9a3508cb14b6\n",
            "Successfully built whisper\n",
            "Installing collected packages: whisper\n",
            "Successfully installed whisper-1.1.10\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libportaudio2 libportaudiocpp0\n",
            "Suggested packages:\n",
            "  portaudio19-doc\n",
            "The following NEW packages will be installed:\n",
            "  libportaudio2 libportaudiocpp0 portaudio19-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 188 kB of archives.\n",
            "After this operation, 927 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudio2 amd64 19.6.0-1.1 [65.3 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudiocpp0 amd64 19.6.0-1.1 [16.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 portaudio19-dev amd64 19.6.0-1.1 [106 kB]\n",
            "Fetched 188 kB in 1s (317 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 121913 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package libportaudiocpp0:amd64.\n",
            "Preparing to unpack .../libportaudiocpp0_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package portaudio19-dev:amd64.\n",
            "Preparing to unpack .../portaudio19-dev_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Setting up portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "Collecting pyaudio\n",
            "  Downloading PyAudio-0.2.14.tar.gz (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyaudio\n",
            "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyaudio: filename=PyAudio-0.2.14-cp310-cp310-linux_x86_64.whl size=63860 sha256=741be24f5b8dd2cd4b5ec731fcc845756838932e78a48d49c10bf42f67553b68\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/21/f4/0b51d41ba79e51b16295cbb096ec49f334792814d545b508c5\n",
            "Successfully built pyaudio\n",
            "Installing collected packages: pyaudio\n",
            "Successfully installed pyaudio-0.2.14\n",
            "\u001b[2K     \u001b[32m-\u001b[0m \u001b[32m14.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m \u001b[33m0:00:03\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.1/119.1 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.1/760.1 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.3/802.3 kB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyannote.audio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: whisper in /usr/local/lib/python3.10/dist-packages (1.1.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from whisper) (1.16.0)\n",
            "\u001b[31mERROR: Invalid requirement: 'speechbrain=0.5.16'\n",
            "Hint: = is not a valid operator. Did you mean == ?\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install whisper\n",
        "!pip install pydub\n",
        "!sudo apt install portaudio19-dev\n",
        "!pip install pyaudio\n",
        "!pip install -qq https://github.com/pyannote/pyannote-audio/archive/refs/heads/develop.zip\n",
        "!pip install --upgrade whisper\n",
        "!pip install speechbrain=0.5.16"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import whisper\n",
        "import os\n",
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "import pyaudio\n",
        "import subprocess\n",
        "import torch\n",
        "import pyannote.audio\n",
        "from pyannote.audio.pipelines.speaker_verification import PretrainedSpeakerEmbedding\n",
        "from pyannote.audio import Audio\n",
        "from pyannote.core import Segment\n",
        "import wave\n",
        "import contextlib\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import random"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUKAnFBC6sg-",
        "outputId": "0c3e42cf-04e1-4be1-b1ad-5f4813fbbfef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: speechbrain 1.0.0\n",
            "Uninstalling speechbrain-1.0.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/speechbrain-1.0.0.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/speechbrain/*\n",
            "    /usr/local/lib/python3.10/dist-packages/tests/*\n",
            "  Would not remove (might be manually added):\n",
            "    /usr/local/lib/python3.10/dist-packages/tests/test_optimizer.py\n",
            "    /usr/local/lib/python3.10/dist-packages/tests/test_pipeline.py\n",
            "    /usr/local/lib/python3.10/dist-packages/tests/utils.py\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled speechbrain-1.0.0\n",
            "Collecting speechbrain==0.5.16\n",
            "  Downloading speechbrain-0.5.16-py3-none-any.whl (630 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m630.6/630.6 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: hyperpyyaml in /usr/local/lib/python3.10/dist-packages (from speechbrain==0.5.16) (1.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from speechbrain==0.5.16) (1.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from speechbrain==0.5.16) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from speechbrain==0.5.16) (24.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from speechbrain==0.5.16) (1.11.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from speechbrain==0.5.16) (0.1.99)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from speechbrain==0.5.16) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from speechbrain==0.5.16) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from speechbrain==0.5.16) (4.66.4)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from speechbrain==0.5.16) (0.23.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain==0.5.16) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain==0.5.16) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain==0.5.16) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain==0.5.16) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain==0.5.16) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain==0.5.16) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain==0.5.16) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain==0.5.16) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain==0.5.16) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain==0.5.16) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain==0.5.16) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain==0.5.16) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain==0.5.16) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain==0.5.16) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain==0.5.16) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain==0.5.16) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain==0.5.16) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain==0.5.16) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9->speechbrain==0.5.16) (12.5.40)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain==0.5.16) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain==0.5.16) (2.31.0)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.10/dist-packages (from hyperpyyaml->speechbrain==0.5.16) (0.18.6)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain==0.5.16) (0.2.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->speechbrain==0.5.16) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain==0.5.16) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain==0.5.16) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain==0.5.16) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain==0.5.16) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->speechbrain==0.5.16) (1.3.0)\n",
            "Installing collected packages: speechbrain\n",
            "Successfully installed speechbrain-0.5.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU_hNmQSFV6V",
        "outputId": "375fe702-7598-415b-9c95-bbf68ac44157"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of channels: 1\n",
            "speakers are :: ['SPEAKER 1', 'SPEAKER 2', 'SPEAKER 1', 'SPEAKER 2', 'SPEAKER 1', 'SPEAKER 2', 'SPEAKER 1']\n",
            "ds are :: ['SPEAKER 1', 0.0, 5.0, 'SPEAKER 2', 5.0, 7.0]\n",
            "\n",
            "SPEAKER 1 0:00:00\n",
            "So you hear about recent updates from Reserve Bank of India regarding UPI payments? \n",
            "SPEAKER 2 0:00:05\n",
            "No, what's new? \n",
            "SPEAKER 1 0:00:07\n",
            "Well, the RBI has increased the limit for automatic payments through UPI to rupees 1 lakh per transaction from the earlier rupees 15,000, especially for certain categories like mutual fund subscriptions. \n",
            "SPEAKER 2 0:00:23\n",
            "Wow, that's a significant jump. It will definitely make things more convenient for many, especially those dealing with higher value transaction. \n",
            "SPEAKER 1 0:00:33\n",
            "Absolutely. And there's another interesting bit. The relaxation and additional factor of authentication for subsequent recurring transactions up to rupees 15,000 on cards, repair instruments and UPI remains in place. \n",
            "SPEAKER 2 0:00:51\n",
            "There's no need to know. It will continue to streamline recurring payments for smaller amounts without the hassle of additional authentication. \n",
            "SPEAKER 1 0:00:59\n",
            "Exactly. UPI has gained immense popularity lately. You know, in November alone, there were over 11... \n",
            "\n",
            "the sample rate is : 8000\n",
            "Skipping audio playback: No Default Output Device Available\n",
            "Skipping audio playback: No Default Output Device Available\n",
            "['William White', 0.0, 5.0, 'Alexander Smith', 5.0, 7.0]\n",
            "['William White', 'Alexander Smith']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Input ids are automatically padded from 129 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            "Input ids are automatically padded from 68 to 1024 to be a multiple of `config.attention_window`: 1024\n"
          ]
        }
      ],
      "source": [
        "def speaker_diarization(path, number, language, size):\n",
        "    path = path\n",
        "\n",
        "    num_speakers = 2  # @param {type:\"integer\"}\n",
        "    language = \"English\"  # @param ['any', 'English']\n",
        "    model_size = \"base\"  # @param ['tiny', 'base', 'small', 'medium', 'large']\n",
        "\n",
        "    model_name = model_size\n",
        "    if language == 'English' and model_size != 'medium':\n",
        "        model_name += '.en'\n",
        "\n",
        "    embedding_model = PretrainedSpeakerEmbedding(\"speechbrain/spkrec-ecapa-voxceleb\", device=torch.device(\"cpu\"))\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"pszemraj/led-base-book-summary\")\n",
        "    audio = AudioSegment.from_file(path, format=\"wav\")\n",
        "    channels = audio.channels\n",
        "    print(\"Number of channels:\", channels)\n",
        "\n",
        "    # If the audio has more than one channel, convert it to a single-channel audio\n",
        "    if channels > 1:\n",
        "        audio = audio.set_channels(1)\n",
        "        audio.export('mono_audio.wav', format=\"wav\")\n",
        "        path = 'mono_audio.wav'\n",
        "\n",
        "    # List of first names and last names\n",
        "    first_names = [\"Emma\", \"Liam\", \"Ava\", \"Noah\", \"Sophia\", \"William\", \"Isabella\", \"James\", \"Mia\", \"Benjamin\",\n",
        "                   \"Charlotte\", \"Oliver\", \"Amelia\", \"Evelyn\", \"Henry\", \"Harper\", \"Ella\", \"Alexander\", \"Abigail\", \"Michael\"]\n",
        "    last_names = [\"Smith\", \"Johnson\", \"Brown\", \"Garcia\", \"Miller\", \"Davis\", \"Rodriguez\", \"Martinez\", \"Hernandez\", \"Lopez\",\n",
        "                  \"Gonzalez\", \"Perez\", \"Taylor\", \"Anderson\", \"Wilson\", \"Jackson\", \"White\", \"Harris\", \"Martin\", \"Thompson\"]\n",
        "\n",
        "    # Function to generate a random name\n",
        "    def generate_name():\n",
        "        first_name = random.choice(first_names)\n",
        "        last_name = random.choice(last_names)\n",
        "        return f\"{first_name} {last_name}\"\n",
        "\n",
        "    if path[-3:] != 'wav':\n",
        "        subprocess.call(['ffmpeg', '-i', path, 'audio.wav', '-y'])\n",
        "        path = 'audio.wav'\n",
        "\n",
        "    model = whisper.load_model(model_size)\n",
        "\n",
        "    result = model.transcribe(path)\n",
        "    segments = result[\"segments\"]\n",
        "\n",
        "    with contextlib.closing(wave.open(path, 'r')) as f:\n",
        "        frames = f.getnframes()\n",
        "        rate = f.getframerate()\n",
        "        duration = frames / float(rate)\n",
        "\n",
        "    audio = Audio()\n",
        "\n",
        "    def segment_embedding(segment):\n",
        "        start = segment[\"start\"]\n",
        "        # Whisper overshoots the end timestamp in the last segment\n",
        "        end = min(duration, segment[\"end\"])\n",
        "        clip = Segment(start, end)\n",
        "        waveform, samplerate = audio.crop(path, clip)\n",
        "        return embedding_model(waveform[None])\n",
        "\n",
        "    embeddings = np.zeros(shape=(len(segments), 192))\n",
        "    for i, segment in enumerate(segments):\n",
        "        embeddings[i] = segment_embedding(segment)\n",
        "\n",
        "    embeddings = np.nan_to_num(embeddings)\n",
        "\n",
        "    clustering = AgglomerativeClustering(num_speakers).fit(embeddings)\n",
        "    labels = clustering.labels_\n",
        "    for i in range(len(segments)):\n",
        "        segments[i][\"speaker\"] = 'SPEAKER ' + str(labels[i] + 1)\n",
        "\n",
        "    def time(secs):\n",
        "        return timedelta(seconds=round(secs))\n",
        "\n",
        "    f = open(\"transcript.txt\", \"w\", encoding='utf-8')\n",
        "    speakers = []\n",
        "    distinct_speakers = []\n",
        "    for (i, segment) in enumerate(segments):\n",
        "        if i == 0 or segments[i - 1][\"speaker\"] != segment[\"speaker\"]:\n",
        "            f.write(\"\\n\" + segment[\"speaker\"] + ' ' + str(time(segment[\"start\"])) + '\\n')\n",
        "            temp1 = time(segment[\"start\"])\n",
        "            temp2 = time(segment[\"end\"])\n",
        "            speakers.append(segment[\"speaker\"])\n",
        "        f.write(segment[\"text\"][1:] + ' ')\n",
        "        temp = set(speakers)\n",
        "        for x in temp:\n",
        "            if x not in distinct_speakers:\n",
        "                distinct_speakers.append(segment[\"speaker\"])\n",
        "                distinct_speakers.append(segment[\"start\"])\n",
        "                distinct_speakers.append(segment[\"end\"])\n",
        "\n",
        "    print(\"speakers are ::\", speakers)\n",
        "    print(\"ds are ::\", distinct_speakers)\n",
        "    f.close()\n",
        "\n",
        "    print(open(\"transcript.txt\", 'r', encoding='utf-8').read())\n",
        "\n",
        "    print()\n",
        "    # Regex pattern to match the speaker and dialogue\n",
        "    pattern = re.compile(r'SPEAKER (\\d+) 0:(\\d\\d):(\\d\\d)\\n(.*)')\n",
        "    # Open the file for reading\n",
        "    with open(\"transcript.txt\", \"r\", encoding='utf-8') as f:\n",
        "        content = f.read()\n",
        "\n",
        "    # Dictionary to store the dialogues for each speaker\n",
        "    dialogues = {}\n",
        "\n",
        "    # Loop through all the matches in the content\n",
        "    for match in re.finditer(pattern, content):\n",
        "        speaker = \"SPEAKER \" + str(match.group(1))\n",
        "        dialogue = match.group(4)\n",
        "\n",
        "        # If the speaker is not already in the dictionary, add it and start a list\n",
        "        if speaker not in dialogues:\n",
        "            dialogues[speaker] = []\n",
        "\n",
        "        # Add the dialogue to the list for this speaker\n",
        "        dialogues[speaker].append(dialogue)\n",
        "\n",
        "    data, samplerate = sf.read(path)\n",
        "    print(\"the sample rate is :\", samplerate)\n",
        "    audio_file = AudioSegment.from_file(path, format=\"wav\")\n",
        "    speaker_names = []\n",
        "    val = len(distinct_speakers) // 3\n",
        "\n",
        "    for i in range(val):\n",
        "        j = 1 + i * 3\n",
        "        start_time_str = str(distinct_speakers[j])\n",
        "        end_time_str = str(distinct_speakers[j + 1])\n",
        "        start_time = float(start_time_str)\n",
        "        end_time = float(end_time_str)\n",
        "        segment = audio_file[start_time * 1000:end_time * 1000]\n",
        "\n",
        "        try:\n",
        "            p = pyaudio.PyAudio()\n",
        "            device_index = p.get_default_output_device_info()['index']\n",
        "            stream = p.open(output_device_index=device_index, format=pyaudio.paInt16, channels=2, rate=35000, output=True)\n",
        "            stream.write(segment.raw_data)\n",
        "            stream.stop_stream()\n",
        "            stream.close()\n",
        "            p.terminate()\n",
        "        except OSError as e:\n",
        "            print(f\"Skipping audio playback: {e}\")\n",
        "\n",
        "        name = generate_name()\n",
        "        speaker_names.append(name)\n",
        "        export_file = name + \".mp3\"\n",
        "        segment.export(export_file, format=\"mp3\")\n",
        "\n",
        "    for i in range(val):\n",
        "        distinct_speakers[i * 3] = speaker_names[i]\n",
        "\n",
        "    print(distinct_speakers)\n",
        "    print(speaker_names)\n",
        "\n",
        "    i = 0\n",
        "\n",
        "    for speaker, speaker_dialogues in dialogues.items():\n",
        "        with open(speaker_names[i] + \".txt\", \"w\", encoding='utf-8') as f:\n",
        "            f.write(speaker_names[i] + \":\" + \"\\n\")\n",
        "            f.write(\"\\n\".join(speaker_dialogues))\n",
        "        i = i + 1\n",
        "\n",
        "    with open(\"transcript.txt\", \"r\", encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\"pszemraj/led-base-book-summary\")\n",
        "    input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "    summary_ids = model.generate(input_ids, num_beams=4, length_penalty=2.0, max_length=142, min_length=56,\n",
        "                                 early_stopping=True)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    with open(\"summary.txt\", \"w\", encoding='utf-8') as f:\n",
        "        for sentence in summary:\n",
        "            f.write(str(sentence))\n",
        "\n",
        "    for m in range(len(speaker_names)):\n",
        "        if (os.path.exists(speaker_names[m] + \".txt\")):\n",
        "            with open(speaker_names[m] + \".txt\", \"r\", encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "            input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "            summary_ids = model.generate(input_ids, num_beams=4, length_penalty=2.0, max_length=142, min_length=56,\n",
        "                                         early_stopping=True)\n",
        "            summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "            with open(speaker_names[m] + \"summary\" + \".txt\", \"w\", encoding='utf-8') as f:\n",
        "                for sentence in summary:\n",
        "                    f.write(str(sentence))\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    individual_summary_files_store = []\n",
        "    individual_script_files_store = []\n",
        "    actions_files_store = []\n",
        "\n",
        "    for name in speaker_names:\n",
        "        actions_files_store.append(name + \"actions.txt\")\n",
        "        individual_script_files_store.append(name + \".txt\")\n",
        "        individual_summary_files_store.append(name + \"summary.txt\")\n",
        "\n",
        "    transcript_file = 'transcript.txt'\n",
        "    summary_file = 'summary.txt'\n",
        "    actions_files = actions_files_store\n",
        "    individual_script_files = individual_script_files_store\n",
        "    individual_summary_files = individual_summary_files_store\n",
        "\n",
        "    def generate_json(transcript_file, summary_file, actions_files, individual_script_files, individual_summary_files):\n",
        "\n",
        "      with open(\"output.json\", 'r') as json_file:\n",
        "        data = json.load(json_file)\n",
        "        final_json = json.dumps(data, indent=4)\n",
        "\n",
        "      return final_json\n",
        "\n",
        "speaker_diarization('/content/myaudio.wav', 2, 'English', 'base')"
      ]
    }
  ]
}